MedleyDB
==============
A dataset of multitrack audio for annotation-intensive MIR research.
**Version** 1.0
**Release Date** 01 September 2014
**Authors** Rachel M. Bittner, Justin Salamon, Mike Tierney, Matthias Mauch, Chris Cannam, and Juan P. Bello
**Contact** rachel (dot) bittner (at) nyu (dot) edu
http://marl.smusic.nyu.edu/medleydb

Please cite the following paper in academic research:
R. Bittner, J. Salamon, M. Tierney, M. Mauch, C. Cannam and J. P. Bello, "MedleyDB: A Multitrack Dataset for Annotation-Intensive MIR Research", in 15th International Society for Music Information Retrieval Conference, Taipei, Taiwan, Oct. 2014.

Melody Annotations
==============

The melody annotations provided in MedleyDB are “continuous” f0 annotations. Each time frame is given a frequency value in Hz, creating pitch contours. 

Three different types of melody annotations are given based upon the definitions of melody described below.  

General
--------------
- first time stamp: 0 seconds
- time stamp step size: ~5.8 milliseconds (256 samples at a sample rate of 44100)
- time stamps are in units of seconds
- pitch values are in Hz
- a pitch of 0.0 indicates no pitch

All melody annotations were generated using pitch annotations of individual stems. The pitch annotations can be found in the directory “Annotations/Pitch_Annotations”. For more information on the pitch annotations, refer to the section below titled “Pitch Annotations”.

Format
--------------
The annotations are given as comma separated files. For all 3 types of melody, the first column is the time stamp. For Melody 1 and Melody 2, the second column is the pitch value of the melody. For Melody 3, columns 2 through n are pitch annotations of each of the melodic voices, ranked by prominence.

Melody 1
--------------
Melody Definition: “The f0 curve of the predominant melodic line drawn from a single source”

This type of melody annotation is the pitch of the stem with the most predominant melodic source. The choice of most predominant melodic stem was made by the same annotator across the dataset. The ranking of stems by melodic prominence for each track is given in the directory “Annotations/Stem_Rankings”, with the most predominant stem labeled with rank “1”.

This definition of melody works when there is one clear predominant melodic source, such as in a pop song with a clear vocal melody. However, this definition is lacking for more complex music, where multiple voices/instruments may play the melody during the course of the song. 

Melody 2
--------------
Melody Definition: “The f0 curve of the predominant melodic line drawn from multiple sources”

This type of melody annotation was generated by first annotating the predominant melodic stem over time. For example:
start_time, end_time, stem_index
0.0, 23.4, 4
23.4, 103.9, 9
103.9, 108.0, 4
etc.
These melody intervals by stem are given in the directory “Annotations/Stem_Intervals”.

For each time interval, the pitch annotation of the indicated stem is assigned to the melody. Thus, at each point in time, this type of melody annotation gives the pitch of the current most predominant melodic source. 

This melody annotation is the best balance between completeness of melody and simplicity (only one melodic source may be present at a time). Even so, this definition cannot capture more complicated music, where multiple sources may be playing melodic content at once. For example, contrapuntal music seldom has a single clear melody, and more commonly pop music often has two vocalists singing the melody in octaves.

Melody 3
--------------
Melody Definition: “The f0 curves of all melodic lines drawn from multiple sources”

This definition is the most general, giving all possible melodies at a time. This annotation is simply an ordered concatenation of the pitch annotations of the stems containing melody. The ordering of predominance is given in the directory “Annotations/Stem_Rankings”.


Pitch Annotations
==============

The pitch annotations here are “continuous” f0 annotations. Each small time frame is given a frequency value in Hz, creating pitch contours.  

General
--------------
- only pitched time stamps are given
- first time stamp: at first timestamp with a nonzero pitch value
- time stamp step size: ~5.8 milliseconds (256 samples at a sample rate of 44100)
- time stamps are in units of seconds
- pitch values are in Hz

Format
--------------
The pitch annotations are given as comma separated files where column 1 is time in seconds and column 2 is pitch in Hz.

Annotation Protocols
--------------
**The pitch was annotated only when melodic content was present.** The choice of what content was “melodic” was determined by the annotators, with the rule of thumb that if they were in doubt to call it melodic. If the stem contained multiple pitches (for example a piano playing both melody and accompaniment, the predominant (monophonic) melodic line was annotated.

Pitch annotations were created using Tony versions 0.5 and 0.6(https://code.soundsoftware.ac.uk/projects/tony). Reverb tail and consonant vocal sounds were considered un-pitched.

Each track was assigned to one of 5 annotators. The assigned annotator created pitch annotations for all melodic stems for the track. Once complete, these annotations were checked and possibly cleaned by a different annotator. The validated annotations are considered the final annotations.

Viewing the annotations
--------------
These annotations can be plotted and sonified within Tony by loading the corresponding stem, choosing File > Import Pitch Track… and selecting the .csv annotation file.


Stem Intervals
==============
These annotations indicate the predominant melodic stem for each time interval. The boundaries for each time interval occur when the primary melodic content changes voice.

The annotations were created in Audacity. For consistency, one annotator created these annotations for every track in the dataset.

Format
--------------
These annotations are given as tab separated files where column 1 is interval start time, column 2 is interval end time, and column 3 is the index of the stem with the primary melodic content during that time interval.


Stem Rankings
==============
These annotations indicate the ranking of melodic predominance for each of the stems containing melody. For example, if there are n stems with melodic content, each of these stems are ranked from 1 to n from most to least predominant melody. A track with 2 melodic stems, say vocals and guitar where the vocals have the melody for all but a solo section where the guitar has a solo, vocals would be given rank 1 and guitar would be given rank 2.

For consistency, one annotator labeled the rankings for every track in the dataset.

Format
--------------
These annotations are give as comma separated files where column 1 is the pitch annotation file name and column 2 is the rank.
