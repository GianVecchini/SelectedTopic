{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://drive.google.com/file/d/1-lmvLqHRoVztabnwQ8RbZuDhpsd1kmYY/view?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1kpc8L4BIgP"
   },
   "source": [
    "**Research project** for the course of *Selected Topics in Music and Acoustic Engineering* :\n",
    "\n",
    "***Music Instrument Classification***\n",
    "---\n",
    "Team:\n",
    "* Andrea Crisafulli\n",
    "* Marco Porcella\n",
    "* Giacomo De Toni\n",
    "* Gianluigi Vecchini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zV3R57F_h9nz"
   },
   "source": [
    "### *Import libraries*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1741789150083,
     "user": {
      "displayName": "gianluigi vecchini",
      "userId": "14572864369043101278"
     },
     "user_tz": -60
    },
    "id": "XSbySaOmh9n0"
   },
   "outputs": [],
   "source": [
    "# === Core Python & Scientific Computing ===\n",
    "import numpy as np                # Numerical computing\n",
    "import pandas as pd              # Data handling and manipulation\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "from pathlib import Path         # File path handling\n",
    "import scipy.signal as signal    # Signal processing tools\n",
    "\n",
    "# === Audio Processing ===\n",
    "import librosa                   # Audio analysis\n",
    "import librosa.display           # Visualization for librosa outputs\n",
    "import IPython.display as ipd    # For audio playback in notebooks\n",
    "\n",
    "# === Scikit-learn: ML & Preprocessing ===\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay  # Evaluation\n",
    "from sklearn.decomposition import PCA         # Dimensionality reduction\n",
    "from sklearn.preprocessing import scale, StandardScaler, MultiLabelBinarizer  # Data scaling & encoding\n",
    "from sklearn.model_selection import train_test_split  # Dataset splitting\n",
    "from sklearn.svm import SVC                    # Support Vector Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier  # k-NN classifier\n",
    "from sklearn.cluster import KMeans            # Clustering\n",
    "\n",
    "# === Deep Learning: TensorFlow / Keras ===\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint  # Training utilities\n",
    "from keras.optimizers import Adam            # Optimizer for model training\n",
    "from keras import layers, models\n",
    "\n",
    "# === Optional: PyTorch (if used) ===\n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "#import torch.nn.functional as F              # Functional API for building models\n",
    "\n",
    "# === Others ===\n",
    "import yaml                                   # Parsing metadata in YAML format\n",
    "from collections import Counter               # Frequency counting for label analysis\n",
    "from tqdm import tqdm                         # Progress bar for loops\n",
    "\n",
    "# === Plotting Style ===\n",
    "plt.style.use(\"seaborn-v0_8\")                 # Set default plotting style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yc88qhCUSlQi"
   },
   "source": [
    "### Import audio data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2879 audio files.\n"
     ]
    }
   ],
   "source": [
    "basePath = Path(\"E:/MedleyDB\")                         # For windows\n",
    "#basePath = Path(\"/Volumes/Extreme SSD/MedleyDB\")        # For mac\n",
    "audioPath = basePath / \"Audio\"\n",
    "data = []\n",
    "\n",
    "# Iterates over directories in the melodyDB/Audio folder\n",
    "for songDir in audioPath.iterdir():\n",
    "    labelArray = []\n",
    "    \n",
    "    # Security check to skip not directory items\n",
    "    if not songDir.is_dir():\n",
    "        continue\n",
    "    \n",
    "    songName = songDir.name\n",
    "    yamlFilePath = audioPath / songDir / f\"{songName}_METADATA.yaml\" # Path to YAML metadata file\n",
    "    \n",
    "    # Opens YAML metadata file in read mode\n",
    "    with open(yamlFilePath, \"r\") as f:\n",
    "        metadata = yaml.safe_load(f)\n",
    "    \n",
    "    # Recovers stems from metadata and stores in dictionary\n",
    "    stemsData = metadata.get(\"stems\", {})\n",
    "    \n",
    "    # Iterates over stems\n",
    "    for stemId, stem in stemsData.items():\n",
    "        instrumentData = [] # Empty data for raw paths\n",
    "        \n",
    "        rawData = stem.get(\"raw\", {})\n",
    "        # Iterates over raw items to store the relative paths\n",
    "        for rawId, raw in rawData.items():\n",
    "            rawPath = songDir /  f\"{songName}_RAW\" / raw.get(\"filename\")\n",
    "            \n",
    "            # Checks for valid files\n",
    "            if(not rawPath.name.startswith(\".\")):\n",
    "                newData = {\n",
    "                    \"song\": songName,\n",
    "                    \"songPath\": audioPath / songDir,\n",
    "                    \"label\": stem.get(\"instrument\"),\n",
    "                    \"filePath\": rawPath\n",
    "                }\n",
    "                \n",
    "                data.append(newData)\n",
    "        \n",
    "        # Creates new data\n",
    "        newData = {\n",
    "            \"song\": songName,\n",
    "            \"songPath\": songDir,\n",
    "            \"label\": stem.get(\"instrument\"),\n",
    "            \"filePath\": songDir / f\"{songName}_STEMS\" / stem.get(\"filename\")\n",
    "        }\n",
    "        \n",
    "        # Appends to data \n",
    "        data.append(newData)\n",
    "        \n",
    "        labelArray.append(stem.get(\"instrument\"))\n",
    "    \n",
    "    # Format    \n",
    "    labelFormatted = \"|\".join(sorted(set(labelArray)))\n",
    "    \n",
    "    mixData = {\n",
    "        \"song\": songName,\n",
    "        \"songPath\": audioPath / songDir,\n",
    "        \"label\": labelFormatted,\n",
    "        \"filePath\": songDir / f\"{songName}_MIX.wav\"\n",
    "    }\n",
    "    \n",
    "    data.append(mixData)\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Loaded {len(df)} audio files.\")\n",
    "\n",
    "# String convertion to list\n",
    "df[\"labelList\"] = df[\"label\"].str.split(\"|\")\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "audioLabelsBinary = mlb.fit_transform(df[\"labelList\"])\n",
    "audioLabelsBinary = np.asarray(audioLabelsBinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>songPath</th>\n",
       "      <th>label</th>\n",
       "      <th>filePath</th>\n",
       "      <th>labelList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AClassicEducation_NightOwl</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl</td>\n",
       "      <td>electric bass</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl\\A...</td>\n",
       "      <td>[electric bass]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AClassicEducation_NightOwl</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl</td>\n",
       "      <td>electric bass</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl\\A...</td>\n",
       "      <td>[electric bass]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AClassicEducation_NightOwl</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl</td>\n",
       "      <td>electric bass</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl\\A...</td>\n",
       "      <td>[electric bass]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AClassicEducation_NightOwl</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl</td>\n",
       "      <td>drum set</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl\\A...</td>\n",
       "      <td>[drum set]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AClassicEducation_NightOwl</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl</td>\n",
       "      <td>drum set</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl\\A...</td>\n",
       "      <td>[drum set]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         song                                      songPath  \\\n",
       "0  AClassicEducation_NightOwl  E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl   \n",
       "1  AClassicEducation_NightOwl  E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl   \n",
       "2  AClassicEducation_NightOwl  E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl   \n",
       "3  AClassicEducation_NightOwl  E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl   \n",
       "4  AClassicEducation_NightOwl  E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl   \n",
       "\n",
       "           label                                           filePath  \\\n",
       "0  electric bass  E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl\\A...   \n",
       "1  electric bass  E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl\\A...   \n",
       "2  electric bass  E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl\\A...   \n",
       "3       drum set  E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl\\A...   \n",
       "4       drum set  E:\\MedleyDB\\Audio\\AClassicEducation_NightOwl\\A...   \n",
       "\n",
       "         labelList  \n",
       "0  [electric bass]  \n",
       "1  [electric bass]  \n",
       "2  [electric bass]  \n",
       "3       [drum set]  \n",
       "4       [drum set]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>songPath</th>\n",
       "      <th>label</th>\n",
       "      <th>filePath</th>\n",
       "      <th>labelList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>Wolf_DieBekherte</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\Wolf_DieBekherte</td>\n",
       "      <td>piano</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\Wolf_DieBekherte\\Wolf_DieBek...</td>\n",
       "      <td>[piano]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>Wolf_DieBekherte</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\Wolf_DieBekherte</td>\n",
       "      <td>piano</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\Wolf_DieBekherte\\Wolf_DieBek...</td>\n",
       "      <td>[piano]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>Wolf_DieBekherte</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\Wolf_DieBekherte</td>\n",
       "      <td>piano</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\Wolf_DieBekherte\\Wolf_DieBek...</td>\n",
       "      <td>[piano]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>Wolf_DieBekherte</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\Wolf_DieBekherte</td>\n",
       "      <td>piano</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\Wolf_DieBekherte\\Wolf_DieBek...</td>\n",
       "      <td>[piano]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>Wolf_DieBekherte</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\Wolf_DieBekherte</td>\n",
       "      <td>female singer|piano</td>\n",
       "      <td>E:\\MedleyDB\\Audio\\Wolf_DieBekherte\\Wolf_DieBek...</td>\n",
       "      <td>[female singer, piano]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  song                            songPath  \\\n",
       "2874  Wolf_DieBekherte  E:\\MedleyDB\\Audio\\Wolf_DieBekherte   \n",
       "2875  Wolf_DieBekherte  E:\\MedleyDB\\Audio\\Wolf_DieBekherte   \n",
       "2876  Wolf_DieBekherte  E:\\MedleyDB\\Audio\\Wolf_DieBekherte   \n",
       "2877  Wolf_DieBekherte  E:\\MedleyDB\\Audio\\Wolf_DieBekherte   \n",
       "2878  Wolf_DieBekherte  E:\\MedleyDB\\Audio\\Wolf_DieBekherte   \n",
       "\n",
       "                    label                                           filePath  \\\n",
       "2874                piano  E:\\MedleyDB\\Audio\\Wolf_DieBekherte\\Wolf_DieBek...   \n",
       "2875                piano  E:\\MedleyDB\\Audio\\Wolf_DieBekherte\\Wolf_DieBek...   \n",
       "2876                piano  E:\\MedleyDB\\Audio\\Wolf_DieBekherte\\Wolf_DieBek...   \n",
       "2877                piano  E:\\MedleyDB\\Audio\\Wolf_DieBekherte\\Wolf_DieBek...   \n",
       "2878  female singer|piano  E:\\MedleyDB\\Audio\\Wolf_DieBekherte\\Wolf_DieBek...   \n",
       "\n",
       "                   labelList  \n",
       "2874                 [piano]  \n",
       "2875                 [piano]  \n",
       "2876                 [piano]  \n",
       "2877                 [piano]  \n",
       "2878  [female singer, piano]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2879 entries, 0 to 2878\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   song       2879 non-null   object\n",
      " 1   songPath   2879 non-null   object\n",
      " 2   label      2879 non-null   object\n",
      " 3   filePath   2879 non-null   object\n",
      " 4   labelList  2879 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 112.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files and labels for a total lenght of 2879\n"
     ]
    }
   ],
   "source": [
    "audioFiles = []\n",
    "audioLabels = []\n",
    "\n",
    "# Extract paths and labels\n",
    "for _, row in df.iterrows():\n",
    "    audioFiles.append(row[\"filePath\"])\n",
    "    audioLabels.append(row[\"labelList\"])\n",
    "    \n",
    "\n",
    "# Security check\n",
    "if(len(audioFiles) == len(audioLabels)):\n",
    "    print(f\"Extracted files and labels for a total lenght of {len(audioFiles)}\")\n",
    "else:\n",
    "    print(\"Error in dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top labels: ['drum set', 'vocalists', 'electric bass']\n",
      "Extracted 876 samples from top 3 labels\n",
      "Subset binary label matrix shape: (876, 82)\n"
     ]
    }
   ],
   "source": [
    "n_classes_test = 3\n",
    "\n",
    "# Flatten all labels e conta frequenze\n",
    "all_labels = sum(df[\"labelList\"], [])\n",
    "label_counts = Counter(all_labels)\n",
    "\n",
    "# Prendi le 10 classi più frequenti\n",
    "top_labels = [label for label, _ in label_counts.most_common(n_classes_test)]\n",
    "print(\"Top labels:\", top_labels)\n",
    "\n",
    "# Filtra righe dove almeno una label è in top_labels\n",
    "df_subset = df[df[\"labelList\"].apply(lambda labels: any(label in top_labels for label in labels))]\n",
    "\n",
    "# Estrai audio e label\n",
    "audioFilesSubset = df_subset[\"filePath\"].tolist()\n",
    "audioLabelsSubset = df_subset[\"labelList\"].tolist()\n",
    "audioLabelsSubsetBinary = audioLabelsBinary[df_subset.index]\n",
    "audioLabelsSubsetBinary = np.asarray(audioLabelsSubsetBinary)\n",
    "\n",
    "if len(audioFilesSubset) == len(audioLabelsSubset):\n",
    "    print(f\"Extracted {len(audioFilesSubset)} samples from top {n_classes_test} labels\")\n",
    "else:\n",
    "    print(\"Mismatch in extracted data\")\n",
    "\n",
    "print(f\"Subset binary label matrix shape: {audioLabelsSubsetBinary.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv-timbre (Python 3.10.11)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Giacomo/OneDrive/Documenti/GitHub/SelectedTopic/venv-timbre/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "audioFilesToExtract = audioFilesSubset # TESTING\n",
    "#audioFilesToExtract = audioFiles # REAL\n",
    "\n",
    "signals = []\n",
    "\n",
    "#for file in tqdm(audioFilesSubset, desc=\"Loading audio files...\"):\n",
    "#    y, _ = librosa.load(file, sr=22050)\n",
    "#    signals.append(y)\n",
    "\n",
    "for x in tqdm(audioFilesSubset[0:10], desc=\"Loading audio files...\"):\n",
    "    y, _ = librosa.load(x, sr=22050)\n",
    "    signals.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melSpegrams = []\n",
    "\n",
    "# Iterates over signals, normalizes them and computes mel spectrograms via librosa feature\n",
    "for signal in tqdm(signals, desc=\"Processing audio signals...\"):\n",
    "    # Normalization of signal n\n",
    "    if np.max(np.abs(signal)) > 0:\n",
    "        signal = signal / np.max(np.abs(signal))\n",
    "\n",
    "    # Creation of mel spectrogram\n",
    "    S = librosa.feature.melspectrogram(y=signal, sr=22050)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    melSpegrams.append(S_dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of spectrogram n=0\n",
    "import IPython.display\n",
    "\n",
    "for i in range(0, len(signals), len(signals)/10):\n",
    "    print(\"\\n\\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\")\n",
    "    \n",
    "    IPython.display.display(IPython.display.Audio(signals[i], rate=22050))\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    librosa.display.specshow(melSpegrams[i], sr=22050, x_axis='time', y_axis='mel', fmax=22050/2)\n",
    "    plt.clim(-60,None)\n",
    "    plt.colorbar()\n",
    "\n",
    "    filename = str(audioFilesSubset[i]).split(\"\\\\\")[-1]\n",
    "    \n",
    "    plt.title(f'{filename} (data #{i})')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user now has to choose which data he wants to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE WHICH DATA TO LOAD\n",
    "#labelsToLoad = audioLabelsBinary\n",
    "labelsToLoad = audioLabelsSubsetBinary[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Compute the maximum length across all mel spectrograms ===\n",
    "# This will define the target temporal dimension for padding\n",
    "maxLen = max(mel.shape[1] for mel in melSpegrams)\n",
    "print(f\"Max mel spectrogram length detected: {maxLen} frames\")\n",
    "\n",
    "# === Define padding function ===\n",
    "# Pads the mel spectrogram to match the target length (right-padding with silence level -80 dB)\n",
    "def pad_mel(mel, targetLen=maxLen):\n",
    "    padWidth = targetLen - mel.shape[1]\n",
    "    if padWidth > 0:\n",
    "        return np.pad(mel, ((0, 0), (0, padWidth)), mode='constant', constant_values=-80)\n",
    "    else:\n",
    "        return mel[:, :targetLen]  # In case some spectrograms are slightly longer\n",
    "\n",
    "# === Apply padding to all mel spectrograms ===\n",
    "# The output list will contain uniformly sized mel spectrograms\n",
    "melSpegramsPadded = [pad_mel(mel) for mel in melSpegrams]\n",
    "\n",
    "# === Convert to NumPy array and add channel dimension ===\n",
    "# Final shape: (N_samples, 128, max_len, 1) — ready for CNN input\n",
    "melSpegramsPadded = np.expand_dims(np.asarray(melSpegramsPadded), axis=-1)\n",
    "print(f\"Padded mel spectrogram array shape: {melSpegramsPadded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Train (70%) and Temp (30%)\n",
    "# X = mel spectrograms\n",
    "# y = label\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    melSpegramsPadded, labelsToLoad, test_size=0.30, random_state=42\n",
    ")\n",
    "\n",
    "# Split Temp into Validation (15%) and Test (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Summary\n",
    "print(f\"Train samples:      {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Test samples:       {len(X_test)}\")\n",
    "print(f\"Test lables:       {len(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define input shape and number of output classes ===\n",
    "inputShape = (128, 43, 1)  # (n_mels, time_frames, channels)\n",
    "numClasses = labelsToLoad.shape[1]  # number of multilabel classes\n",
    "\n",
    "# === Build CNN model ===\n",
    "modelCNN = models.Sequential([\n",
    "\n",
    "    # Input\n",
    "    layers.Input(shape=inputShape),\n",
    "\n",
    "    # === Block 1 ===\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((3, 3), padding='same'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    # === Block 2 ===\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((3, 3), padding='same'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    # === Block 3 ===\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((3, 3), padding='same'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    # === Block 4 ===\n",
    "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    layers.GlobalMaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    # === Fully Connected ===\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    # === Output Layer (sigmoid for multilabel) ===\n",
    "    layers.Dense(numClasses, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# === Compile the model ===\n",
    "modelCNN.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# === Summary ===\n",
    "modelCNN.summary()\n",
    "\n",
    "# Optional: show classes\n",
    "print(f\"Number of classes: {numClasses}\")\n",
    "print(f\"Class names: {mlb.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Path to save logs and models\n",
    "csvLogPath = 'training_log.csv'\n",
    "checkpointPath = 'best_model.h5'\n",
    "\n",
    "# CSVLogger: logs every epoch to CSV\n",
    "csvLogger = CSVLogger(csvLogPath, append=True)\n",
    "\n",
    "# EarlyStopping: stop if val_loss doesn't improve after 100 epochs\n",
    "earlyStop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=100,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ModelCheckpoint: save best model based on val_accuracy\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpointPath,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Bundle them\n",
    "callbacks = [csvLogger, earlyStop, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# Compile the model\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "modelCNN.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batchSize=32\n",
    "epochs=300\n",
    "\n",
    "history = modelCNN.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batchSize, epochs=epochs, verbose=0, callbacks = callbacks)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "iNJ-d4zDUwAl"
   ],
   "provenance": [
    {
     "file_id": "1eg4ysGRmcU-8BENj7XWR0P7goV391s_I",
     "timestamp": 1741182208526
    }
   ]
  },
  "kernelspec": {
   "display_name": "venv-timbre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
